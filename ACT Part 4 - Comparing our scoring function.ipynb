{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from helpers import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams.update({'font.size': 8})\n",
    "import itertools\n",
    "codeToggler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(df, survey, objNames, trial_types) = loadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate surprisal for all trials_types. \n",
    "surprisals = {}\n",
    "likelihoods = {}\n",
    "for pics in trial_types:\n",
    "    trial_type = pics[0][:-1]\n",
    "    likelihoods[trial_type] = correspondenceProbabilities(pics[0], pics[1], df, objNames)\n",
    "    surprisals[trial_type] = -np.log(likelihoods[trial_type])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate the analogy surprisal for all trials\n",
    "scores = []\n",
    "for i, row in df.iterrows():\n",
    "    surprisal = surprisals[row['trial_type']]\n",
    "    scores += [analogyScore(row['analogies'], surprisal)]\n",
    "df['analogy_score'] = scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How good is this score?\n",
    "Comparing our scoring function with naive surprisal and frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['analogies_str'] = df['analogies'].astype(str)\n",
    "\n",
    "# Analogy scores. Taking averages doesn't change a thing.\n",
    "analogy_scores = df[df['trial_type'] == 'KA'].groupby('analogies_str').mean()['analogy_score']\n",
    "\n",
    "# Frequencies\n",
    "frequencies = df[df['trial_type'] == 'KA'].groupby('analogies_str').count()['analogies']\n",
    "\n",
    "# Comparison dataframe\n",
    "compare = pd.DataFrame(index=analogy_scores.index)\n",
    "compare['score'] = analogy_scores\n",
    "compare['frequency'] = frequencies\n",
    "compare ['surprisal'] = -np.log( frequencies / sum(frequencies) )\n",
    "compare = compare.sort_values(by='frequency', ascending=False)\n",
    "compare.index = compare.index.str.replace(\"u''\", u'\\u00D7').str.replace('[', '(').str.replace(']', ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "ax = compare.plot(secondary_y=['score', 'surprisal'], figsize=(7,3.5), style='-o', lw=1.1)\n",
    "\n",
    "# Labels\n",
    "ax.right_ax.set_ylabel('score and surprisal values')\n",
    "ax.set_ylabel('frequency')\n",
    "ax.set_xlabel('')\n",
    "ax.set_xticks(range(len(compare.index)))\n",
    "ax.set_xticklabels(compare.index, rotation=-40, horizontalalignment='left')\n",
    "ax.set_xlim([-.3,10.3])\n",
    "ax.right_ax.set_ylim([0,5])\n",
    "\n",
    "# Legends\n",
    "legend = plt.legend(bbox_to_anchor=(1.10,1.05), loc='upper left')\n",
    "legend.get_frame().set_color('white')\n",
    "legend2 = ax.legend(bbox_to_anchor=(1.10,.85), loc='upper left')\n",
    "legend2.get_frame().set_color('white')\n",
    "\n",
    "# Title\n",
    "plt.title('Score, frequencies and surprisal value for different analogies', y=1.08);\n",
    "\n",
    "# Save plot\n",
    "plt.tight_layout()\n",
    "plt.savefig('exports/scoring-comparison.png', format='png', dpi=300,\n",
    "    bbox_extra_artists=(legend,), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save\n",
    "df.to_json('data/trials-with-scores.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
